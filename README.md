# üí∞ Financial Audit Trail & Fraud Detection Data Pipeline

## Project Overview
This project implements a *medallion (Bronze-Silver-Gold) data pipeline* to process, clean, and analyze synthetic financial transaction data for *audit trail and fraud detection* purposes. It simulates a high-volume transaction environment across multiple users, identifies invalid and suspicious transactions, and provides analytical summaries for monitoring and reporting.

## *Key Outcomes:*
- Processed *500,000+ transactions across 10,000 users*  
- Detected *28,400 suspicious transactions (5.68%)* and *10,094 invalid records (2.02%)*  
- Generated *gold-layer aggregates* for daily KPI monitoring and fraud classification  
- Normalized and validated transaction data ensuring *analytics-ready datasets*  

---

## üõ† Tech Stack
- *Python 3.x* ‚Äì Data processing and simulation scripts  
- *MySQL* ‚Äì Storage of raw and cleaned transaction data  
- *PySpark* ‚Äì Data transformations and medallion pipeline  
- *SQL* ‚Äì Analytical queries and aggregation  
- *Power BI* ‚Äì Dashboard visualization of KPIs and fraud summaries  


## ‚öôÔ∏è Setup & Usage

### 1Ô∏è‚É£ Clone the repository
```bash
git clone <https://github.com/minerva1404/Financial-Audit-Trail-Fraud-Detection-Data-pipeline>
cd financial-audit-fraud-pipeline
```
### 2Ô∏è‚É£ Set up Python environment
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
pip install -r requirements.txt
```
### 3Ô∏è‚É£ Load Raw Transaction Data

-- Run this in MySQL to create synthetic transactions\
source: fintech_bronze.sql;

### 4Ô∏è‚É£ Transform to Silver Layer

-- Run the silver transformation queries\
source: fintech_silver.sql;

### 5Ô∏è‚É£ Aggregate Gold Layer

-- Run the gold aggregation queries\
source : fintech_gold.sql;

### 6Ô∏è‚É£ Visualize KPIs
	‚Ä¢	Open fintech_dashboard.pbix in Power BI to view metrics like fraud distribution, daily transactions, and top-risk accounts.



## üìä Analytical Highlights
‚Ä¢	Fraud Classification: Normal, Negative Balance, Extreme Amount, High Amount.\
‚Ä¢	Transaction Quality: Invalid Users, Missing Timestamps, Negative Amounts.\
‚Ä¢	Daily Metrics: Total transactions, volume, average transaction amount, suspicious transactions.\
‚Ä¢	KPI Insights: Fraud percent, invalid percent, high-value transactions, and anomaly detection.



## üîç Key Learnings:
‚Ä¢	Built end-to-end medallion architecture from raw to analytical gold layer.\
‚Ä¢	Applied fraud detection logic with multiple thresholds and anomaly detection.\
‚Ä¢	Ensured data quality and validation for analytics-ready datasets.\
‚Ä¢	Generated quantitative insights for monitoring and reporting.

## üìà Result Metrics (Sample)

Metric	Value:
Total Transactions	500,000\
Invalid Records	10,094 (2.02%)\
Suspicious Transactions	28,400 (5.68%)\
Normal Transactions	94.32%\
Negative Balance	2.97%\
Extreme Amount	1.53%\
High Amount	1.18%


## üí° Next Steps / Extensions:
‚Ä¢	Integrate real-time streaming ingestion using Kafka or Spark Streaming.\
‚Ä¢	Add predictive fraud scoring using machine learning models.\
‚Ä¢	Build alerting dashboards with automated notifications for anomalous transactions.
